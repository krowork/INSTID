{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca81327e",
   "metadata": {},
   "source": [
    "# InstantID: Zero-shot Identity-Preserving Generation in Seconds\n",
    "\n",
    "Este script implementa [InstantID](https://github.com/InstantX/InstantID), un m√©todo para generar im√°genes \n",
    "que preservan la identidad de una persona en segundos.\n",
    "\n",
    "‚ö†Ô∏è **Importante**: Aseg√∫rate de seleccionar un entorno de ejecuci√≥n con GPU: Runtime -> Change runtime type -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que tenemos GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"GPU disponible: {torch.cuda.is_available()}\")\n",
    "print(f\"Dispositivo CUDA: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No hay GPU'}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"No se detect√≥ GPU. Por favor, selecciona un entorno de ejecuci√≥n con GPU: Runtime -> Change runtime type -> GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar el repositorio\n",
    "!git clone https://github.com/krowork/INSTID.git\n",
    "%cd INSTID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que estamos en un entorno con GPU\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"\\n‚ùå Este notebook requiere una GPU. Por favor, selecciona: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# Desinstalar paquetes conflictivos del sistema\n",
    "print(\"\\n1. Limpiando entorno...\")\n",
    "!pip uninstall -y torch torchvision torchaudio transformers diffusers accelerate safetensors numpy websockets insightface opencv-python gradio controlnet-aux huggingface_hub onnx onnxruntime timm datasets tsfresh dask-cudf-cu12 raft-dask-cu12\n",
    "\n",
    "# Limpiar la cach√© y archivos temporales\n",
    "print(\"\\n2. Limpiando cach√© y archivos temporales...\")\n",
    "!pip cache purge\n",
    "!rm -rf ~/.cache/pip\n",
    "!rm -rf /tmp/pip-*\n",
    "!rm -rf ~/.cache/huggingface\n",
    "!rm -rf ~/.cache/torch\n",
    "!rm -rf ~/.cache/clip\n",
    "\n",
    "# Crear un entorno limpio\n",
    "print(\"\\n3. Configurando entorno...\")\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = './torch_home'\n",
    "os.environ['HF_HOME'] = './hf_home'\n",
    "!mkdir -p ./torch_home ./hf_home\n",
    "\n",
    "# Instalaci√≥n base\n",
    "print(\"\\n4. Instalando dependencias base...\")\n",
    "!pip install --no-cache-dir torch==2.0.1+cu118 torchvision==0.15.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install --no-cache-dir numpy==1.26.0\n",
    "\n",
    "# Verificar instalaci√≥n de PyTorch\n",
    "print(\"\\n5. Verificando instalaci√≥n de PyTorch...\")\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA no est√° disponible despu√©s de la instalaci√≥n\")\n",
    "\n",
    "# Instalaci√≥n de dependencias principales\n",
    "print(\"\\n6. Instalando dependencias principales...\")\n",
    "!pip install --no-cache-dir -U huggingface_hub==0.19.4\n",
    "!pip install --no-cache-dir -U transformers==4.36.2\n",
    "!pip install --no-cache-dir -U diffusers==0.24.0\n",
    "!pip install --no-cache-dir -U accelerate==0.25.0\n",
    "!pip install --no-cache-dir -U safetensors==0.4.1\n",
    "\n",
    "# Instalaci√≥n de dependencias adicionales\n",
    "print(\"\\n7. Instalando dependencias adicionales...\")\n",
    "!pip install --no-cache-dir websockets==11.0.3\n",
    "!pip install --no-cache-dir opencv-python==4.8.0.74\n",
    "!pip install --no-cache-dir insightface==0.7.3\n",
    "!pip install --no-cache-dir controlnet_aux==0.0.7\n",
    "!pip install --no-cache-dir onnx\n",
    "!pip install --no-cache-dir onnxruntime-gpu\n",
    "!pip install --no-cache-dir gradio==4.19.2\n",
    "\n",
    "# Verificaci√≥n final\n",
    "print(\"\\n8. Verificaci√≥n final de instalaciones...\")\n",
    "try:\n",
    "    import huggingface_hub\n",
    "    print(f\"‚úì huggingface_hub: {huggingface_hub.__version__}\")\n",
    "    import transformers\n",
    "    print(f\"‚úì transformers: {transformers.__version__}\")\n",
    "    from diffusers import __version__ as diffusers_version\n",
    "    print(f\"‚úì diffusers: {diffusers_version}\")\n",
    "    import torch\n",
    "    print(f\"‚úì PyTorch: {torch.__version__}\")\n",
    "    print(f\"‚úì CUDA disponible: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  - Dispositivo: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  - Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error en verificaci√≥n: {str(e)}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è ¬°IMPORTANTE!\")\n",
    "print(\"1. ES NECESARIO reiniciar el entorno de ejecuci√≥n: Runtime -> Restart runtime\")\n",
    "print(\"2. Despu√©s de reiniciar, ejecuta la siguiente celda para verificar la instalaci√≥n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprimir advertencias no cr√≠ticas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"Verificando instalaci√≥n...\")\n",
    "\n",
    "# Verificar versiones base\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nVersiones b√°sicas:\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "\n",
    "# Verificar GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"\\n‚ùå No se detect√≥ GPU. Este notebook requiere una GPU para funcionar.\")\n",
    "\n",
    "print(f\"\\n‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memoria GPU total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"Memoria GPU disponible: {torch.cuda.mem_get_info()[0] / 1024**3:.1f} GB\")\n",
    "print(f\"CUDA versi√≥n: {torch.version.cuda}\")\n",
    "print(f\"cuDNN versi√≥n: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else 'No disponible'}\")\n",
    "\n",
    "# Verificar CUDA\n",
    "print(\"\\nVerificando CUDA...\")\n",
    "try:\n",
    "    x = torch.rand(5,3).cuda()\n",
    "    y = torch.matmul(x, x.t())\n",
    "    print(\"‚úÖ CUDA est√° funcionando correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al usar CUDA: {e}\")\n",
    "\n",
    "# Verificar dependencias cr√≠ticas\n",
    "print(\"\\nVerificando dependencias cr√≠ticas...\")\n",
    "import huggingface_hub\n",
    "print(f\"‚úì huggingface_hub: {huggingface_hub.__version__}\")\n",
    "\n",
    "import onnxruntime\n",
    "print(f\"‚úì onnxruntime: {onnxruntime.__version__}\")\n",
    "\n",
    "# Verificar dependencias principales\n",
    "print(\"\\nVerificando dependencias principales...\")\n",
    "from diffusers import __version__ as diffusers_version\n",
    "print(f\"‚úì diffusers: {diffusers_version}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"‚úì transformers: {transformers.__version__}\")\n",
    "\n",
    "import cv2\n",
    "print(f\"‚úì opencv-python: {cv2.__version__}\")\n",
    "\n",
    "import insightface\n",
    "print(f\"‚úì insightface: {insightface.__version__}\")\n",
    "\n",
    "import controlnet_aux\n",
    "print(f\"‚úì controlnet_aux: {controlnet_aux.__version__}\")\n",
    "\n",
    "import gradio as gr\n",
    "print(f\"‚úì gradio: {gr.__version__}\")\n",
    "\n",
    "print(\"\\nVerificaci√≥n completada.\")\n",
    "\n",
    "# Verificar que las versiones sean las esperadas\n",
    "expected_versions = {\n",
    "    'huggingface_hub': '0.19.4',\n",
    "    'transformers': '4.36.2',\n",
    "    'diffusers': '0.24.0',\n",
    "    'torch': '2.0.1+cu118',\n",
    "    'numpy': '1.26.0',\n",
    "    'opencv-python': '4.8.0',  # Actualizado para ser m√°s flexible\n",
    "    'insightface': '0.7.3',\n",
    "    'controlnet_aux': '0.0.7',\n",
    "    'gradio': '4.19.2'\n",
    "}\n",
    "\n",
    "def version_matches(current, expected):\n",
    "    \"\"\"Compara versiones con cierta flexibilidad.\"\"\"\n",
    "    if current == expected:\n",
    "        return True\n",
    "    # Para opencv, comparamos solo los primeros tres n√∫meros de versi√≥n\n",
    "    if 'opencv' in current:\n",
    "        current_parts = current.split('.')[:3]\n",
    "        expected_parts = expected.split('.')[:3]\n",
    "        return current_parts == expected_parts\n",
    "    return False\n",
    "\n",
    "print(\"\\nVerificando versiones esperadas:\")\n",
    "all_correct = True\n",
    "for package, expected_version in expected_versions.items():\n",
    "    if package == 'torch':\n",
    "        current_version = torch.__version__\n",
    "    elif package == 'numpy':\n",
    "        current_version = np.__version__\n",
    "    elif package == 'opencv-python':\n",
    "        current_version = cv2.__version__\n",
    "    elif package == 'huggingface_hub':\n",
    "        current_version = huggingface_hub.__version__\n",
    "    elif package == 'transformers':\n",
    "        current_version = transformers.__version__\n",
    "    elif package == 'diffusers':\n",
    "        current_version = diffusers_version\n",
    "    elif package == 'insightface':\n",
    "        current_version = insightface.__version__\n",
    "    elif package == 'controlnet_aux':\n",
    "        current_version = controlnet_aux.__version__\n",
    "    elif package == 'gradio':\n",
    "        current_version = gr.__version__\n",
    "\n",
    "    if not version_matches(current_version, expected_version):\n",
    "        print(f\"‚ö†Ô∏è {package}: versi√≥n actual {current_version}, esperada {expected_version}\")\n",
    "        all_correct = False\n",
    "    else:\n",
    "        print(f\"‚úÖ {package}: {current_version}\")\n",
    "\n",
    "if all_correct:\n",
    "    print(\"\\n‚úÖ Todas las versiones son correctas!\")\n",
    "    print(\"\\nüöÄ El entorno est√° listo para usar InstantID!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Algunas versiones no coinciden con las esperadas.\")\n",
    "    print(\"Si todo funciona correctamente, puedes continuar. Si encuentras problemas, considera reinstalar las dependencias.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44c427",
   "metadata": {},
   "source": [
    "## Importar Dependencias\n",
    "Ejecuta esta celda despu√©s de reiniciar el entorno de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import transformers\n",
    "from diffusers import __version__ as diffusers_version\n",
    "from diffusers.utils import load_image\n",
    "from diffusers.models import ControlNetModel\n",
    "from insightface.app import FaceAnalysis\n",
    "# Importar el pipeline desde el repositorio clonado\n",
    "from pipeline_stable_diffusion_xl_instantid import StableDiffusionXLInstantIDPipeline, draw_kps\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Verificar que todo est√° correcto\n",
    "print(f\"PyTorch CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Dispositivo CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "print(f\"\\nVersiones de las dependencias:\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"transformers: {transformers.__version__}\")\n",
    "print(f\"diffusers: {diffusers_version}\")\n",
    "print(f\"torch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7baad",
   "metadata": {},
   "source": [
    "## Configuraci√≥n de Modelos\n",
    "En esta secci√≥n vamos a:\n",
    "1. Descargar los modelos necesarios\n",
    "2. Configurar el pipeline de InstantID\n",
    "3. Preparar el analizador facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configurando modelos...\")\n",
    "\n",
    "# Crear directorios para checkpoints y modelos\n",
    "import os\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints/ControlNetModel\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Descargar modelos necesarios\n",
    "print(\"\\nDescargando modelos necesarios...\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_files = [\n",
    "    {\"filename\": \"ControlNetModel/config.json\", \"repo_id\": \"InstantX/InstantID\"},\n",
    "    {\"filename\": \"ControlNetModel/diffusion_pytorch_model.safetensors\", \"repo_id\": \"InstantX/InstantID\"},\n",
    "    {\"filename\": \"ip-adapter.bin\", \"repo_id\": \"InstantX/InstantID\"}\n",
    "]\n",
    "\n",
    "for file_info in model_files:\n",
    "    print(f\"Descargando {file_info['filename']}...\")\n",
    "    hf_hub_download(\n",
    "        repo_id=file_info['repo_id'],\n",
    "        filename=file_info['filename'],\n",
    "        local_dir=\"./checkpoints\",\n",
    "        resume_download=True\n",
    "    )\n",
    "\n",
    "# Configurar el analizador facial\n",
    "print(\"\\nConfigurando analizador facial...\")\n",
    "import os\n",
    "import zipfile\n",
    "from insightface.app import FaceAnalysis\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "# Descargar el modelo buffalo_l\n",
    "model_dir = os.path.abspath(\"./models\")\n",
    "model_name = \"buffalo_l\"\n",
    "model_file = os.path.join(model_dir, f\"{model_name}.zip\")\n",
    "\n",
    "if not os.path.exists(os.path.join(model_dir, model_name)):\n",
    "    print(f\"Descargando modelo {model_name}...\")\n",
    "    url = \"https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip\"\n",
    "    \n",
    "    # Crear directorio temporal\n",
    "    temp_dir = os.path.join(model_dir, \"temp\")\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Descargar y extraer en directorio temporal\n",
    "    urllib.request.urlretrieve(url, model_file)\n",
    "    with zipfile.ZipFile(model_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "    \n",
    "    # Mover archivos a la ubicaci√≥n correcta\n",
    "    for file in os.listdir(temp_dir):\n",
    "        src = os.path.join(temp_dir, file)\n",
    "        dst = os.path.join(model_dir, file)\n",
    "        if os.path.exists(dst):\n",
    "            os.remove(dst)\n",
    "        shutil.move(src, dst)\n",
    "    \n",
    "    # Limpiar\n",
    "    os.remove(model_file)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(\"Modelo descargado y configurado correctamente.\")\n",
    "\n",
    "# Inicializar el analizador facial\n",
    "print(\"\\nInicializando analizador facial...\")\n",
    "global app\n",
    "app = FaceAnalysis(name=model_name, root=model_dir, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "print(\"Analizador facial inicializado correctamente.\")\n",
    "\n",
    "# Cargar ControlNet\n",
    "print(\"\\nCargando ControlNet...\")\n",
    "import torch\n",
    "from diffusers.models import ControlNetModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "global controlnet\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    'checkpoints/ControlNetModel',\n",
    "    torch_dtype=dtype,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "# Cargar el pipeline principal\n",
    "print(\"\\nCargando pipeline principal...\")\n",
    "from pipeline_stable_diffusion_xl_instantid import StableDiffusionXLInstantIDPipeline\n",
    "\n",
    "global pipe\n",
    "pipe = StableDiffusionXLInstantIDPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=dtype,\n",
    "    safety_checker=None,\n",
    "    feature_extractor=None\n",
    ")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    pipe.cuda()\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    pipe.enable_vae_tiling()\n",
    "\n",
    "# Cargar IP-Adapter\n",
    "print(\"\\nCargando IP-Adapter...\")\n",
    "pipe.load_ip_adapter_instantid('checkpoints/ip-adapter.bin')\n",
    "\n",
    "print(\"\\n‚úÖ ¬°Todos los modelos han sido cargados correctamente!\")\n",
    "print(\"Ahora puedes proceder a generar im√°genes.\")\n",
    "\n",
    "# Verificar que las variables globales est√°n disponibles\n",
    "print(\"\\nVerificando variables globales:\")\n",
    "print(f\"Pipeline disponible: {'pipe' in globals()}\")\n",
    "print(f\"Analizador facial disponible: {'app' in globals()}\")\n",
    "print(f\"ControlNet disponible: {'controlnet' in globals()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97685d5b",
   "metadata": {},
   "source": [
    "## Funci√≥n de Generaci√≥n de Im√°genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(face_image_path, prompt, negative_prompt=None, num_steps=30, identitynet_strength_ratio=0.80, adapter_strength_ratio=0.80):\n",
    "    \"\"\"Genera una imagen usando InstantID.\"\"\"\n",
    "    if negative_prompt is None:\n",
    "        negative_prompt = \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry\"\n",
    "    \n",
    "    print(\"Cargando imagen...\")\n",
    "    face_image = load_image(face_image_path)\n",
    "    face_image_cv2 = cv2.cvtColor(np.array(face_image), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    print(\"Detectando rostro...\")\n",
    "    face_info = app.get(face_image_cv2)\n",
    "    if len(face_info) == 0:\n",
    "        raise ValueError(\"No se detect√≥ ning√∫n rostro en la imagen\")\n",
    "    \n",
    "    face_info = face_info[-1]\n",
    "    face_emb = face_info['embedding']\n",
    "    face_kps = draw_kps(face_image, face_info['kps'])\n",
    "    \n",
    "    print(\"Configurando par√°metros...\")\n",
    "    pipe.set_ip_adapter_scale(adapter_strength_ratio)\n",
    "    \n",
    "    print(\"Generando imagen...\")\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        image_embeds=face_emb,\n",
    "        image=face_kps,\n",
    "        controlnet_conditioning_scale=float(identitynet_strength_ratio),\n",
    "        num_inference_steps=num_steps,\n",
    "        guidance_scale=5.0\n",
    "    ).images[0]\n",
    "    \n",
    "    print(\"¬°Generaci√≥n completada!\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642fab8",
   "metadata": {},
   "source": [
    "## Interfaz Web con Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que tenemos las variables necesarias\n",
    "if 'pipe' not in globals():\n",
    "    raise RuntimeError(\"El pipeline no est√° inicializado. Aseg√∫rate de ejecutar la celda de configuraci√≥n de modelos primero.\")\n",
    "if 'app' not in globals():\n",
    "    raise RuntimeError(\"El analizador facial no est√° inicializado. Aseg√∫rate de ejecutar la celda de configuraci√≥n de modelos primero.\")\n",
    "\n",
    "# Importaciones necesarias\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from diffusers.utils import load_image\n",
    "import logging\n",
    "import traceback\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar logging para mostrar en el notebook\n",
    "class NotebookHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        try:\n",
    "            msg = self.format(record)\n",
    "            print(f\"{datetime.now().strftime('%H:%M:%S')} - {msg}\")\n",
    "            sys.stdout.flush()\n",
    "        except Exception:\n",
    "            self.handleError(record)\n",
    "\n",
    "# Configurar logger\n",
    "logger = logging.getLogger('InstantID')\n",
    "logger.setLevel(logging.INFO)\n",
    "# Eliminar handlers existentes para evitar duplicados\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "handler = NotebookHandler()\n",
    "formatter = logging.Formatter('%(levelname)s: %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Verificar el estado inicial\n",
    "logger.info(\"=== Verificando estado inicial ===\")\n",
    "logger.info(f\"Pipeline disponible: {pipe is not None}\")\n",
    "logger.info(f\"Analizador facial disponible: {app is not None}\")\n",
    "logger.info(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"Memoria GPU disponible: {torch.cuda.mem_get_info()[0] / 1024**3:.2f} GB\")\n",
    "\n",
    "def generate_image(face_image_path, prompt, negative_prompt=None, num_steps=30, identitynet_strength_ratio=0.80, adapter_strength_ratio=0.80):\n",
    "    \"\"\"Genera una imagen usando InstantID.\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Iniciando generaci√≥n de imagen...\")\n",
    "        logger.info(f\"Par√°metros: prompt='{prompt}', steps={num_steps}, identity_strength={identitynet_strength_ratio}, adapter_strength={adapter_strength_ratio}\")\n",
    "        \n",
    "        if negative_prompt is None:\n",
    "            negative_prompt = \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry\"\n",
    "        \n",
    "        logger.info(\"Cargando imagen...\")\n",
    "        face_image = load_image(face_image_path)\n",
    "        logger.info(\"Imagen cargada correctamente\")\n",
    "        \n",
    "        logger.info(\"Convirtiendo imagen para detecci√≥n facial...\")\n",
    "        face_image_cv2 = cv2.cvtColor(np.array(face_image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        logger.info(\"Detectando rostro...\")\n",
    "        face_info = app.get(face_image_cv2)\n",
    "        if len(face_info) == 0:\n",
    "            raise ValueError(\"No se detect√≥ ning√∫n rostro en la imagen\")\n",
    "        logger.info(\"Rostro detectado correctamente\")\n",
    "        \n",
    "        face_info = face_info[-1]\n",
    "        face_emb = face_info['embedding']\n",
    "        face_kps = draw_kps(face_image, face_info['kps'])\n",
    "        logger.info(\"Puntos faciales extra√≠dos correctamente\")\n",
    "        \n",
    "        logger.info(\"Configurando par√°metros del pipeline...\")\n",
    "        pipe.set_ip_adapter_scale(adapter_strength_ratio)\n",
    "        \n",
    "        logger.info(\"Generando imagen...\")\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image_embeds=face_emb,\n",
    "            image=face_kps,\n",
    "            controlnet_conditioning_scale=float(identitynet_strength_ratio),\n",
    "            num_inference_steps=num_steps,\n",
    "            guidance_scale=5.0\n",
    "        ).images[0]\n",
    "        \n",
    "        logger.info(\"¬°Generaci√≥n completada!\")\n",
    "        return image\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en generate_image: {str(e)}\")\n",
    "        logger.error(f\"Traza completa:\\n{traceback.format_exc()}\")\n",
    "        raise\n",
    "\n",
    "def process_image(image, prompt, num_steps, identitynet_strength, adapter_strength):\n",
    "    \"\"\"Procesa la imagen para la interfaz Gradio.\"\"\"\n",
    "    try:\n",
    "        logger.info(\"=== Iniciando nuevo procesamiento de imagen ===\")\n",
    "        logger.info(f\"Tipo de imagen recibida: {type(image)}\")\n",
    "        \n",
    "        # Verificar variables globales\n",
    "        if 'pipe' not in globals() or pipe is None:\n",
    "            raise RuntimeError(\"Pipeline no disponible\")\n",
    "        if 'app' not in globals() or app is None:\n",
    "            raise RuntimeError(\"Analizador facial no disponible\")\n",
    "        \n",
    "        logger.info(\"Verificando estado de variables globales...\")\n",
    "        logger.info(f\"Pipeline disponible: {pipe is not None}\")\n",
    "        logger.info(f\"Analizador facial disponible: {app is not None}\")\n",
    "        logger.info(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            logger.info(f\"Memoria GPU disponible: {torch.cuda.mem_get_info()[0] / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # Guardar imagen temporal\n",
    "        temp_path = \"temp_face.png\"\n",
    "        if isinstance(image, str):\n",
    "            temp_path = image\n",
    "            logger.info(f\"Usando ruta de imagen existente: {temp_path}\")\n",
    "        else:\n",
    "            logger.info(\"Guardando imagen temporal...\")\n",
    "            image.save(temp_path)\n",
    "            logger.info(f\"Imagen guardada en: {temp_path}\")\n",
    "        \n",
    "        try:\n",
    "            logger.info(\"Llamando a generate_image...\")\n",
    "            result = generate_image(\n",
    "                face_image_path=temp_path,\n",
    "                prompt=prompt,\n",
    "                num_steps=int(num_steps),\n",
    "                identitynet_strength_ratio=float(identitynet_strength),\n",
    "                adapter_strength_ratio=float(adapter_strength)\n",
    "            )\n",
    "            logger.info(\"Imagen generada exitosamente\")\n",
    "            return result\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error durante la generaci√≥n: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            logger.error(f\"Traza completa:\\n{traceback.format_exc()}\")\n",
    "            return gr.Image.update(value=None, label=error_msg)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error en el procesamiento: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        logger.error(f\"Traza completa:\\n{traceback.format_exc()}\")\n",
    "        return gr.Image.update(value=None, label=error_msg)\n",
    "        \n",
    "    finally:\n",
    "        # Limpiar archivo temporal\n",
    "        if isinstance(image, Image.Image) and os.path.exists(temp_path):\n",
    "            try:\n",
    "                os.remove(temp_path)\n",
    "                logger.info(\"Archivo temporal eliminado\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"No se pudo eliminar el archivo temporal: {str(e)}\")\n",
    "\n",
    "# Crear la interfaz\n",
    "demo = gr.Interface(\n",
    "    fn=process_image,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Imagen del rostro\"),\n",
    "        gr.Textbox(\n",
    "            label=\"Prompt\",\n",
    "            value=\"analog film photo of a person in a cyberpunk city, neon lights, cinematic lighting\"\n",
    "        ),\n",
    "        gr.Slider(minimum=20, maximum=100, value=30, step=1, label=\"N√∫mero de pasos\"),\n",
    "        gr.Slider(minimum=0.0, maximum=1.5, value=0.8, step=0.05, label=\"Fuerza IdentityNet\"),\n",
    "        gr.Slider(minimum=0.0, maximum=1.5, value=0.8, step=0.05, label=\"Fuerza Adapter\")\n",
    "    ],\n",
    "    outputs=gr.Image(type=\"pil\", label=\"Imagen generada\"),\n",
    "    title=\"InstantID - Generaci√≥n de Im√°genes\",\n",
    "    description=\"Sube una imagen con un rostro claro y visible, ajusta los par√°metros y genera una nueva imagen manteniendo la identidad.\"\n",
    ")\n",
    "\n",
    "logger.info(\"Interfaz Gradio inicializada. Lista para procesar im√°genes.\")\n",
    "\n",
    "# Lanzar la interfaz\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a694b6e",
   "metadata": {},
   "source": [
    "## Limpieza de Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Memoria GPU liberada\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
