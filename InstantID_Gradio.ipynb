{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f41a6f",
   "metadata": {},
   "source": [
    "# InstantID: Zero-shot Identity-Preserving Generation in Seconds\n",
    "\n",
    "Este script implementa [InstantID](https://github.com/InstantX/InstantID), un método para generar imágenes \n",
    "que preservan la identidad de una persona en segundos.\n",
    "\n",
    "⚠️ **Importante**: Asegúrate de seleccionar un entorno de ejecución con GPU: Runtime -> Change runtime type -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0da086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que tenemos GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"GPU disponible: {torch.cuda.is_available()}\")\n",
    "print(f\"Dispositivo CUDA: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No hay GPU'}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"No se detectó GPU. Por favor, selecciona un entorno de ejecución con GPU: Runtime -> Change runtime type -> GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar el repositorio\n",
    "!git clone https://github.com/krowork/INSTID.git\n",
    "%cd INSTID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que estamos en un entorno con GPU\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"\\n❌ Este notebook requiere una GPU. Por favor, selecciona: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# Desinstalar paquetes conflictivos del sistema\n",
    "print(\"\\n1. Limpiando entorno...\")\n",
    "!pip uninstall -y torch torchvision torchaudio transformers diffusers accelerate safetensors numpy websockets insightface opencv-python gradio controlnet-aux huggingface_hub onnx onnxruntime timm datasets tsfresh dask-cudf-cu12 raft-dask-cu12\n",
    "\n",
    "# Limpiar la caché y archivos temporales\n",
    "print(\"\\n2. Limpiando caché y archivos temporales...\")\n",
    "!pip cache purge\n",
    "!rm -rf ~/.cache/pip\n",
    "!rm -rf /tmp/pip-*\n",
    "!rm -rf ~/.cache/huggingface\n",
    "!rm -rf ~/.cache/torch\n",
    "!rm -rf ~/.cache/clip\n",
    "\n",
    "# Crear un entorno limpio\n",
    "print(\"\\n3. Configurando entorno...\")\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = './torch_home'\n",
    "os.environ['HF_HOME'] = './hf_home'\n",
    "!mkdir -p ./torch_home ./hf_home\n",
    "\n",
    "# Instalación base\n",
    "print(\"\\n4. Instalando dependencias base...\")\n",
    "!pip install --no-cache-dir torch==2.0.1+cu118 torchvision==0.15.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install --no-cache-dir numpy==1.26.0\n",
    "\n",
    "# Verificar instalación de PyTorch\n",
    "print(\"\\n5. Verificando instalación de PyTorch...\")\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA no está disponible después de la instalación\")\n",
    "\n",
    "# Instalación de dependencias principales\n",
    "print(\"\\n6. Instalando dependencias principales...\")\n",
    "!pip install --no-cache-dir -U huggingface_hub==0.19.4\n",
    "!pip install --no-cache-dir -U transformers==4.36.2\n",
    "!pip install --no-cache-dir -U diffusers==0.24.0\n",
    "!pip install --no-cache-dir -U accelerate==0.25.0\n",
    "!pip install --no-cache-dir -U safetensors==0.4.1\n",
    "\n",
    "# Instalación de dependencias adicionales\n",
    "print(\"\\n7. Instalando dependencias adicionales...\")\n",
    "!pip install --no-cache-dir websockets==11.0.3\n",
    "!pip install --no-cache-dir opencv-python==4.8.0.74\n",
    "!pip install --no-cache-dir insightface==0.7.3\n",
    "!pip install --no-cache-dir controlnet_aux==0.0.7\n",
    "!pip install --no-cache-dir onnx\n",
    "!pip install --no-cache-dir onnxruntime-gpu\n",
    "!pip install --no-cache-dir gradio==4.19.2\n",
    "\n",
    "# Verificación final\n",
    "print(\"\\n8. Verificación final de instalaciones...\")\n",
    "try:\n",
    "    import huggingface_hub\n",
    "    print(f\"✓ huggingface_hub: {huggingface_hub.__version__}\")\n",
    "    import transformers\n",
    "    print(f\"✓ transformers: {transformers.__version__}\")\n",
    "    from diffusers import __version__ as diffusers_version\n",
    "    print(f\"✓ diffusers: {diffusers_version}\")\n",
    "    import torch\n",
    "    print(f\"✓ PyTorch: {torch.__version__}\")\n",
    "    print(f\"✓ CUDA disponible: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  - Dispositivo: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  - Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error en verificación: {str(e)}\")\n",
    "\n",
    "print(\"\\n⚠️ ¡IMPORTANTE!\")\n",
    "print(\"1. ES NECESARIO reiniciar el entorno de ejecución: Runtime -> Restart runtime\")\n",
    "print(\"2. Después de reiniciar, ejecuta la siguiente celda para verificar la instalación\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprimir advertencias no críticas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"Verificando instalación...\")\n",
    "\n",
    "# Verificar versiones base\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nVersiones básicas:\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "\n",
    "# Verificar GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"\\n❌ No se detectó GPU. Este notebook requiere una GPU para funcionar.\")\n",
    "\n",
    "print(f\"\\n✅ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memoria GPU total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"Memoria GPU disponible: {torch.cuda.mem_get_info()[0] / 1024**3:.1f} GB\")\n",
    "print(f\"CUDA versión: {torch.version.cuda}\")\n",
    "print(f\"cuDNN versión: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else 'No disponible'}\")\n",
    "\n",
    "# Verificar CUDA\n",
    "print(\"\\nVerificando CUDA...\")\n",
    "try:\n",
    "    x = torch.rand(5,3).cuda()\n",
    "    y = torch.matmul(x, x.t())\n",
    "    print(\"✅ CUDA está funcionando correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al usar CUDA: {e}\")\n",
    "\n",
    "# Verificar dependencias críticas\n",
    "print(\"\\nVerificando dependencias críticas...\")\n",
    "import huggingface_hub\n",
    "print(f\"✓ huggingface_hub: {huggingface_hub.__version__}\")\n",
    "\n",
    "import onnxruntime\n",
    "print(f\"✓ onnxruntime: {onnxruntime.__version__}\")\n",
    "\n",
    "# Verificar dependencias principales\n",
    "print(\"\\nVerificando dependencias principales...\")\n",
    "from diffusers import __version__ as diffusers_version\n",
    "print(f\"✓ diffusers: {diffusers_version}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"✓ transformers: {transformers.__version__}\")\n",
    "\n",
    "import cv2\n",
    "print(f\"✓ opencv-python: {cv2.__version__}\")\n",
    "\n",
    "import insightface\n",
    "print(f\"✓ insightface: {insightface.__version__}\")\n",
    "\n",
    "import controlnet_aux\n",
    "print(f\"✓ controlnet_aux: {controlnet_aux.__version__}\")\n",
    "\n",
    "import gradio as gr\n",
    "print(f\"✓ gradio: {gr.__version__}\")\n",
    "\n",
    "print(\"\\nVerificación completada.\")\n",
    "\n",
    "# Verificar que las versiones sean las esperadas\n",
    "expected_versions = {\n",
    "    'huggingface_hub': '0.19.4',\n",
    "    'transformers': '4.36.2',\n",
    "    'diffusers': '0.24.0',\n",
    "    'torch': '2.0.1+cu118',\n",
    "    'numpy': '1.26.0',\n",
    "    'opencv-python': '4.8.0',  # Actualizado para ser más flexible\n",
    "    'insightface': '0.7.3',\n",
    "    'controlnet_aux': '0.0.7',\n",
    "    'gradio': '4.19.2'\n",
    "}\n",
    "\n",
    "def version_matches(current, expected):\n",
    "    \"\"\"Compara versiones con cierta flexibilidad.\"\"\"\n",
    "    if current == expected:\n",
    "        return True\n",
    "    # Para opencv, comparamos solo los primeros tres números de versión\n",
    "    if 'opencv' in current:\n",
    "        current_parts = current.split('.')[:3]\n",
    "        expected_parts = expected.split('.')[:3]\n",
    "        return current_parts == expected_parts\n",
    "    return False\n",
    "\n",
    "print(\"\\nVerificando versiones esperadas:\")\n",
    "all_correct = True\n",
    "for package, expected_version in expected_versions.items():\n",
    "    if package == 'torch':\n",
    "        current_version = torch.__version__\n",
    "    elif package == 'numpy':\n",
    "        current_version = np.__version__\n",
    "    elif package == 'opencv-python':\n",
    "        current_version = cv2.__version__\n",
    "    elif package == 'huggingface_hub':\n",
    "        current_version = huggingface_hub.__version__\n",
    "    elif package == 'transformers':\n",
    "        current_version = transformers.__version__\n",
    "    elif package == 'diffusers':\n",
    "        current_version = diffusers_version\n",
    "    elif package == 'insightface':\n",
    "        current_version = insightface.__version__\n",
    "    elif package == 'controlnet_aux':\n",
    "        current_version = controlnet_aux.__version__\n",
    "    elif package == 'gradio':\n",
    "        current_version = gr.__version__\n",
    "\n",
    "    if not version_matches(current_version, expected_version):\n",
    "        print(f\"⚠️ {package}: versión actual {current_version}, esperada {expected_version}\")\n",
    "        all_correct = False\n",
    "    else:\n",
    "        print(f\"✅ {package}: {current_version}\")\n",
    "\n",
    "if all_correct:\n",
    "    print(\"\\n✅ Todas las versiones son correctas!\")\n",
    "    print(\"\\n🚀 El entorno está listo para usar InstantID!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Algunas versiones no coinciden con las esperadas.\")\n",
    "    print(\"Si todo funciona correctamente, puedes continuar. Si encuentras problemas, considera reinstalar las dependencias.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6dbc31",
   "metadata": {},
   "source": [
    "## Descarga del Pipeline\n",
    "Primero necesitamos descargar el archivo del pipeline de InstantID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el archivo del pipeline\n",
    "!wget https://raw.githubusercontent.com/InstantID/InstantID/main/pipeline_stable_diffusion_xl_instantid.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d5f48",
   "metadata": {},
   "source": [
    "## Importar Dependencias\n",
    "Ejecuta esta celda después de reiniciar el entorno de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b57a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from diffusers.utils import load_image\n",
    "from diffusers.models import ControlNetModel\n",
    "from insightface.app import FaceAnalysis\n",
    "from pipeline_stable_diffusion_xl_instantid import StableDiffusionXLInstantIDPipeline, draw_kps\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Verificar que todo está correcto\n",
    "print(f\"PyTorch CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Dispositivo CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "print(f\"\\nVersiones de las dependencias:\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"transformers: {transformers.__version__}\")\n",
    "print(f\"diffusers: {diffusers.__version__}\")\n",
    "print(f\"torch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527dee1",
   "metadata": {},
   "source": [
    "## Configuración de Modelos\n",
    "En esta sección vamos a:\n",
    "1. Descargar los modelos necesarios\n",
    "2. Configurar el pipeline de InstantID\n",
    "3. Preparar el analizador facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a984909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorios para checkpoints\n",
    "import os\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints/ControlNetModel\", exist_ok=True)\n",
    "\n",
    "# Descargar modelos necesarios\n",
    "print(\"Descargando modelos necesarios...\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_files = [\n",
    "    {\"filename\": \"ControlNetModel/config.json\", \"repo_id\": \"InstantX/InstantID\"},\n",
    "    {\"filename\": \"ControlNetModel/diffusion_pytorch_model.safetensors\", \"repo_id\": \"InstantX/InstantID\"},\n",
    "    {\"filename\": \"ip-adapter.bin\", \"repo_id\": \"InstantX/InstantID\"}\n",
    "]\n",
    "\n",
    "for file_info in model_files:\n",
    "    print(f\"Descargando {file_info['filename']}...\")\n",
    "    hf_hub_download(\n",
    "        repo_id=file_info['repo_id'],\n",
    "        filename=file_info['filename'],\n",
    "        local_dir=\"./checkpoints\",\n",
    "        resume_download=True\n",
    "    )\n",
    "\n",
    "# Configurar el analizador facial\n",
    "print(\"\\nConfigurando analizador facial...\")\n",
    "from insightface.app import FaceAnalysis\n",
    "app = FaceAnalysis(name='antelopev2', root='./', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Cargar ControlNet\n",
    "print(\"\\nCargando ControlNet...\")\n",
    "import torch\n",
    "from diffusers.models import ControlNetModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    'checkpoints/ControlNetModel',\n",
    "    torch_dtype=dtype,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "# Cargar el pipeline principal\n",
    "print(\"\\nCargando pipeline principal...\")\n",
    "from pipeline_stable_diffusion_xl_instantid import StableDiffusionXLInstantIDPipeline\n",
    "\n",
    "pipe = StableDiffusionXLInstantIDPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=dtype,\n",
    "    safety_checker=None,\n",
    "    feature_extractor=None\n",
    ")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    pipe.cuda()\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    pipe.enable_vae_tiling()\n",
    "\n",
    "# Cargar IP-Adapter\n",
    "print(\"\\nCargando IP-Adapter...\")\n",
    "pipe.load_ip_adapter_instantid('checkpoints/ip-adapter.bin')\n",
    "\n",
    "print(\"\\n✅ ¡Todos los modelos han sido cargados correctamente!\")\n",
    "print(\"Ahora puedes proceder a generar imágenes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c973b8",
   "metadata": {},
   "source": [
    "## Función de Generación de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(face_image_path, prompt, negative_prompt=None, num_steps=30, identitynet_strength_ratio=0.80, adapter_strength_ratio=0.80):\n",
    "    \"\"\"Genera una imagen usando InstantID.\"\"\"\n",
    "    if negative_prompt is None:\n",
    "        negative_prompt = \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry\"\n",
    "    \n",
    "    print(\"Cargando imagen...\")\n",
    "    face_image = load_image(face_image_path)\n",
    "    face_image_cv2 = cv2.cvtColor(np.array(face_image), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    print(\"Detectando rostro...\")\n",
    "    face_info = app.get(face_image_cv2)\n",
    "    if len(face_info) == 0:\n",
    "        raise ValueError(\"No se detectó ningún rostro en la imagen\")\n",
    "    \n",
    "    face_info = face_info[-1]\n",
    "    face_emb = face_info['embedding']\n",
    "    face_kps = draw_kps(face_image, face_info['kps'])\n",
    "    \n",
    "    print(\"Configurando parámetros...\")\n",
    "    pipe.set_ip_adapter_scale(adapter_strength_ratio)\n",
    "    \n",
    "    print(\"Generando imagen...\")\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        image_embeds=face_emb,\n",
    "        image=face_kps,\n",
    "        controlnet_conditioning_scale=float(identitynet_strength_ratio),\n",
    "        num_inference_steps=num_steps,\n",
    "        guidance_scale=5.0\n",
    "    ).images[0]\n",
    "    \n",
    "    print(\"¡Generación completada!\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91835183",
   "metadata": {},
   "source": [
    "## Interfaz Web con Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, prompt, num_steps, identitynet_strength, adapter_strength):\n",
    "    \"\"\"Procesa la imagen para la interfaz Gradio.\"\"\"\n",
    "    temp_path = \"temp_face.png\"\n",
    "    if isinstance(image, str):\n",
    "        temp_path = image\n",
    "    else:\n",
    "        image.save(temp_path)\n",
    "    \n",
    "    try:\n",
    "        result = generate_image(\n",
    "            face_image_path=temp_path,\n",
    "            prompt=prompt,\n",
    "            num_steps=int(num_steps),\n",
    "            identitynet_strength_ratio=float(identitynet_strength),\n",
    "            adapter_strength_ratio=float(adapter_strength)\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    finally:\n",
    "        if isinstance(image, Image.Image) and os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "# Crear la interfaz\n",
    "demo = gr.Interface(\n",
    "    fn=process_image,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Imagen del rostro\"),\n",
    "        gr.Textbox(\n",
    "            label=\"Prompt\",\n",
    "            value=\"analog film photo of a person in a cyberpunk city, neon lights, cinematic lighting\"\n",
    "        ),\n",
    "        gr.Slider(minimum=20, maximum=100, value=30, step=1, label=\"Número de pasos\"),\n",
    "        gr.Slider(minimum=0.0, maximum=1.5, value=0.8, step=0.05, label=\"Fuerza IdentityNet\"),\n",
    "        gr.Slider(minimum=0.0, maximum=1.5, value=0.8, step=0.05, label=\"Fuerza Adapter\")\n",
    "    ],\n",
    "    outputs=gr.Image(type=\"pil\", label=\"Imagen generada\"),\n",
    "    title=\"InstantID - Generación de Imágenes\",\n",
    "    description=\"Sube una imagen con un rostro claro y visible, ajusta los parámetros y genera una nueva imagen manteniendo la identidad.\"\n",
    ")\n",
    "\n",
    "# Lanzar la interfaz\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57e0a0",
   "metadata": {},
   "source": [
    "## Limpieza de Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ce033",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Memoria GPU liberada\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
